[["index.html", "Education Chapter 1 Introduction", " Education Woomy Michel and Dillon Sparks 2024-06-28 Chapter 1 Introduction We chose education as our research topic because both of us are passionate about educational equity. Furthermore, Dillon is originally from New York City and attended a NYC public school, and he thought it would be interesting to learn more about the same school system that was an integral part of his academic journey. We are especially interested in exploring the intersections of race/ethnicity, disability status, income, and English language learner status with standardized test scores. Standardized testing is extremely important because it has an impact on funding, which directly influences a child’s experience in school. However, these tests are often criticized for favoring some students based on the aforementioned factors. We hope to look through this data and find more insights into whether or not there is any relationship between student performance and student demographics/the demographics of a student’s school or district. "],["proposal.html", "Chapter 2 Proposal 2.1 Research topic 2.2 Data availability", " Chapter 2 Proposal 2.1 Research topic Our research topic is the composition of the NYC school system, in addition to the factors of academic success (measured by standardized testing scores). We know that a school’s ability to impact its students cannot be measured by standardized testing success alone (or lack thereof). Anyone familiar with the NYC DOE knows that all public schools do not have the same access to resources and extracurricular activities that shape a child’s learning experience. Each school in the city is a unique ecosystem that is shaped by its location, the staff/administration, the student body, and the community that surrounds it. The data that we have transformed and analyzed is meant to tell part of the story, not all of it. We hope to provide you with some preliminary insight into the makeup of the NYC public school system, which will inspire you to learn more on your own. 2.2 Data availability Standardized testing scores: ELA and Math test results 2013-2023 For this project, we will be utilizing three datasets: two that include standardized test scores from the New York Department of Education InfoHub and another with student demographics from the NYC DOE. The first two datasets contain English Language Arts (ELA) and Math test scores between 2013 and 2022 from students in 3rd grade to 8th grade at every school. Each year, the Department of Education (DOE) shares test results in hopes of helping “families and educators understand the performance of New York City schools” (NYC InfoHub). Data regarding test results is available at the city, borough, district, and school levels. For this project, we will examine test results at both the school and district levels. The data is updated annually, though it does not include test scores from 2020 and 2021 since exams were not administered or optional due to the COVID-19 pandemic. Its format is tabular, thus it can be exported as a spreadsheet or CSV file. The dataset also includes important information such as the number of students tested, mean scale score for the respective subjects, and the level (i.e. school, district, or borough) at which each student was tested. This dataset is highly credible given that it comes directly from the NYC DOE. Student demographics: Student demographics from 2018-2023 This dataset was also collected by the New York City Department of Education (NYC DOE) and it includes various information about a district’s/school’s student demographics, including race, sex assigned at birth, English language learner status, economic status, and much more. It was collected using the student’s information once they entered the NYC public school system. Due to differences in the timing of when student demographic, address, and census data were pulled, ENI (Economic Need Index) values may vary (2017-18 - 2021-22 Demographic Snapshot). The format of the data is tabular, it can be exported as an excel spreadsheet or CSV file. The data was last updated June 15, 2022. Additionally, the “New York State Education Department begins administering assessments to be identified as an English Language Learner (ELL) in Kindergarten, but students in Pre-K are still included in the denominator for the ELL calculations” (2017/18 - 2021/22 Demographic Snapshot). Pre-K students also do not receive NYC DOE School food, however are included in the poverty calculations. We plan to import the data by downloading the six separate datasets, joining them based on the “Year” and either the “School” or “District” variables (depending on which level the data was collected at). In the end we will have two cleaned datasets, one at the school level and one aggregated by district, each with demographic data and Math/ELA test scores for all grades 3-8, during 2017-18, 2018-2019, 2021-2022, and 2022-2023. . "],["data.html", "Chapter 3 Data 3.1 Sources 3.2 Transformation 3.3 Missing value analysis", " Chapter 3 Data 3.1 Sources The NYC Department of Education was responsible for collecting and publishing this data. The school-level test scores were collected after they were administered and graded, and then this data was used to calculate the district-level test scores. The demographic information was collected using both the student’s information once they entered the NYC public school system, and census data. We chose to use standardized testing data from grades 3-8 over Regent’s scores (the high school equivalent of these elementary and middle school tests) because there are more middle and elementary schools in the city, and thus, more data to work with. The data was pulled from six different spreadsheets, with categorical and numerical data, with a range of 16 to 44 variables. The two largest spreadsheets had 37,000+ observations, while the smallest had only 175. The datasets did not have many issues, as there were only two missing observations in total; both were test scores for a specific school in a specific year (one Math and one ELA). However, there was a great deal of data transformation, merging, and cleaning that needed to be done in order to investigate some of the questions brought forth earlier. 3.2 Transformation Here is a brief overview of the data cleaning and transformation processes. You can find a more detailed version of our steps in Section 7.1 of the Appendix. First, we read in the six different datasets from the sources described in the previous section. Next, we prepped the individual datasets to be joined by filtering, converting variables to the appropriate types, aggregating from individual grade to the school/district level, imputing missing values, removing unnecessary variables, and renaming variables for consistency sake. Additionally, we added columns to each dataset for the percentage of students tested for each exam and the percentage of students of color. Finally, we wrote two new files with the joined data. 3.3 Missing value analysis After importing our two new datasets, we can see that there are no more NA’s in either. ## DBN Year Mean.Scale.Score_e Mean.Scale.Score_m ## 0 0 0 0 ## Total.Enrollment X..Asian ## 0 0 ## District Year Mean.Scale.Score_e Mean.Scale.Score_m ## 0 0 0 0 ## Total.Enrollment X..Asian ## 0 0 However, the missing values are accounted for in the school and district datasets via the “% Missing Race/Ethnicity” and “% tested_e”/“% tested_m” columns. Our approach is to start by looking for missing values by filtering the “% Missing Race/Ethnicity” column and looking at the percentage of missing data. First we will find the minimum and maximum values for missing data in this column to determine the range of missing race/ethnicity data. Using the min() and max() functions, we discovered that the percent of missing data lies between 0% and ~ 6.7% for the school dataset and 0.09% and 2.4% for the district dataset. It’s good to note that the district data doesn’t have a large number of missing values because districts are comprised of schools and data has to be reported to the district each school belongs in. If a large amount of district data was missing, we’d have to question where a bunch of the individual school data went. Before using data visualization methods, we thought it’d be important to look at the missing data in intervals of 0.2 for the school data. We found that: * 2421 rows in the school dataset have no missing values. * 864 rows in the school dataset have between 0% and 2% missing data. * 36 rows in the school dataset have between 2% and 4% missing data. * 4 rows in the school dataset have between 4% and 6% missing data. * 3 rows in the school dataset have more than 6% missing data. For the district data, we thought it’d be nice to look at it by intervals of 0.005. We found that: - 0 rows in the district dataset have no missing values. - 61 rows in the district dataset have between 0% and 0.5% missing data. - 26 rows in the district dataset have between 0.5% and 1% missing data. - 8 rows in the district dataset have between 1% and 1.5% missing data. - 0 rows in the district dataset have between 1.5% and 2% missing data. - 1 row in the district has over 2% missing data. For our exploratory data analysis of the missing testing data, we decided to use a histogram. Histograms are good because they’re able to show frequency distributions. We found that the data was right-skewed. We can conclude from the visualization that majority of the schools are not missing data as it relates to racial and ethnic demographic data. This was also shown in our preliminary process, where we noted 2421 rows were not missing data, which is roughly 73% of our dataset.The remaining 27% of the data was missing about 6.7% of data, which is not too bad. Ridgeline plot for district by the amount of students that tested. The ridgeline plots look at the percentage of students that tested in Math and ELA by district from the 2017-2018, 2018-2019, and 2021-2022 academic years. Originally, we wanted to facet the data by year and see if there were any differences across districts, however there is only one entry per year for each district, so that would not be helpful (or produce a ridgeline plot). We found that the distributions were very similar across both subjects. In neither Math or ELA was there more than 50% students tested. For districts 7 and 8, in both ELA and Math, there is some slight overlap. This means that some of the entries for those two districts may be the same or close in value. In the math scores, we can also see a very small overlap with districts 24 and 25. Both overlaps are miniscule. "],["results.html", "Chapter 4 Results 4.1 Plots and notes: Part 1 (Reading vs. Math test scores &amp; the Covid-19 pandemic) 4.2 Plots + Notes: Part 2 (NYC Student Demographics &amp; Indicators of success)", " Chapter 4 Results 4.1 Plots and notes: Part 1 (Reading vs. Math test scores &amp; the Covid-19 pandemic) In investigating the relationship between Reading and Math scores, we started very broad by asking ourselves if there is a correlation between success on Math &amp; success on ELA. We chose to break this down at the school level, because there is a lot more data for us to work with. The graphs above are three scatterplots of reading vs math test scores, separated based on the year the test was taken. The two main takeaways here are that there seems to be a strong positive correlation between reading and math scores in all three years, as one might expect. In other words, schools that performed well in math usually did well on reading too, and vice-versa. There were a few outliers each year, where some schools did noticeably better on math than on reading. There were also a few, less noticeable, schools who performed slightly better on ELA than on math. Let’s find the correlation between the Math and ELA scores to gain more insight on them analytically: ## [1] &quot;Neither the Math nor the ELA scores are normally distributed in 2018.&quot; ## [1] &quot;Neither the Math nor the ELA scores are normally distributed in 2019.&quot; ## [1] &quot;Neither the Math nor the ELA scores are normally distributed in 2022.&quot; Since the Math and ELA scores are not normally distributed in any year we will use the Pearson’s correlation to determine the linear relationship between scores in each year. This is what we get: 2018 2019 2022 Correlation 0.942789 0.9409192 0.9275288 The second big takeaway from these scatterplots is that math scores were much lower in 2022 than in years prior. There is also more variance in scores in 2022, which is demonstrated by the relatively lower correlation coefficient and the higher variance of our scatterplot than in the other two years. We can likely attribute this to the onset of the Covid-19 global pandemic, which abruptly forced students to adapt to online learning for anywhere between six months to an entire school year. Let’s look at the spread of the scores during these years: 2018 2019 2022 Math 109.71942 106.92718 125.50043 ELA 88.99088 91.94082 93.76607 Looking at this table we can confirm that the variance was higher for Math &amp; ELA in 2022. Now that we’ve investigated the relationship between success on both exams, we want to know which exam students actually performed better on, over the years. Again, we are looking at this data on the school level because there is more data to work with. Looking at our density histograms, we can see that there is a lot of overlap between scores in both subjects in this three year sample size. At first glance, it seems like student’s are performing slightly better on ELA than Math. In order to test the significance of the difference in test scores, we can utilize the t-test. Our null-hypothesis is that the two sample means are equal (or that the test scores are the same). 4.1.1 START HERE Looking at the result of our t-test, we cannot reject the null hypothesis that our two sample means are the same, even at the 1% level of significance! Therefore, there is no evidence of a significant difference between math &amp; reading scores during the three year period that our data comes from. Even when we repeat the test only looking at the year 2022 (where we noticed a bigger difference than years prior in our density histogram), there is still not enough evidence to reject the null hypothesis that the two sample means are the same, once again at the 1% level of significance. ## ## Paired t-test ## ## data: ela_2022 and math_2022 ## t = 42.969, df = 1121, p-value &lt; 2.2e-16 ## alternative hypothesis: true mean difference is not equal to 0 ## 99 percent confidence interval: ## 5.12013 5.77433 ## sample estimates: ## mean difference ## 5.44723 Now that we have seen there is no significant difference in the relationship between math &amp; reading scores, even since the onset of the Covid-19 pandemic, we decided to investigate how scores have changed within one subject over time. We started by creating a Cleveland Dot Plot of Math scores in each district, for the 3 years of data we have. We chose to use the district data here because there are over 1,000 schools and that is not feasible for creating a Cleveland Dot Plot. The first thing that we noticed about this plot was the trend in scores over time; scores increased from 2018 to 2019, then decreased significantly for nearly every district in 2022, so much so that they are far below the 2018 scores! This drop off in 2022 can largely be explained due to Covid-19, but we do not have any proposed evidence for the nearly uniform increase in scores from 2018 to 2019. One notable exception to these observations is District 1, who dropped from 2019 to 2022, but still performed better in 2022 than 2018. There is also a lot of variation in scores between districts, which supports the claim that all public schools do not have access the same resources and quality of education. Next, we did the same for ELA scores: This plot is extremely interesting because many Districts performed better on ELA in 2022 than in years prior! Furthermore, 2019 is the year where students performed the lowest for the majority of the districts, which is the exact opposite of what the Math dot plot told us. It is difficult to conclude why we see these different trends when we break down the data by subject then year. One suggestion is that students’ reading and critical thinking skills were challenged more than ever since the beginning of quarantine, when many people relied on social media posts articles to get the majority of their information regarding the ongoing global crisis. Their relationship with math and any quantitative skills may not have been integrated into their daily lives in the same way. Furthermore, year to year variance in test difficulty may explain some of the variance in scores. (Note; the 2018/2019 ELA scores for District 4 are nearly identical, so it looks like we’re missing a year of data) 4.2 Plots + Notes: Part 2 (NYC Student Demographics &amp; Indicators of success) For the second part of our analysis, we decided to explore the demographics of NYC schools, and how students’ identities impact their success on standardized testing. We started off by trying to learn more about how disability and funding interact in each school. The data includes an “Economic Need Index” (ENI) category that is the Department of Education’s internal metric for determining for creating a student’s individual funding needs. A student’s ENI is calculated using things like their housing status, English language learner status, eligibility for public assistance, and family income. You can learn more about how ENI’s are calculated at the student and school level here: (https://data.cccnewyork.org/data/map/1371/student-economic-need-index#1371/a/5/1622/127/a/a) We created a heatmap of each schools’ percentage of students with a disability vs their ENI There seems to be a slight positive association between ENI and %SWD each year, as noted by the trend from dark to lighter in the region around (0.5,0.15). Furthermore, the shape of the entire cluster itself loosely shows an increase in ENI as %SWD increases. This is interesting because disability status is not one of the explicit factors in calculating a student/school’s ENI. Students with disabilities deserve any necessary accommodations that will supplement their academic experience, yet the NYC DOE doesn’t explicitly factor this into an individual student’s need for funding. One might find it interesting to look at dropout rates of disabled students vs their ENI’s if they wish to learn more. Next, we dove into the racial demographics of each district. We created a new “% POC” column in the data in order to plot race by district (which included the missing racial data group). We acknowledge the limitations of viewing race in the data as binary, which it is certainly not in real life. If one wishes to repeat this process, we would suggest potentially binning the data or creating a new “majority” categorical column that shows the leading racial demographic by percentage in a particular school/district. From these boxplots, you can see that most NYC School Districts are primarily comprised of students of color. This is important to keep in mind when we investigate the relationship between race (as we have defined it here) and standardized testing success in our next plot. There is one outlier district each year, District 31, whose percentage of students of color is below 60 (but increasing each year). Looking back at our Cleveland Dot plots, District 31 performed in the top 11 in both Math &amp; ELA every year, which is above average but not overwhelmingly great. Now, we will look at all of the different student demographics of interest and determine the relationships between them all and test scores. In both of the following parallel coordinate plots, our factors of interest are score, total enrollment, % of students with disabilities, % of English language learners, % of students living in poverty, and % of students of color. We will do this using district data, because there is too much noise in the plot if we do it by district instead. The first plot is for ELA scores, and the second is for Math. The biggest takeaways from this first graph is that there seems to be a negative association between the percentage of students who are English language learners and ELA test scores, there is a strong negative association between ELA test scores and the percentage of students of color, and that the percentage of students living in poverty has a slight negative correlation with the total enrollment. This first observation makes sense because taking a standardized test in a language that you are learning is an objectively difficult thing to do. The second observation is problematic when we consider our previous graph, showing that all districts are majority students of color; why is there a negative association between % of POC students and test scores in a majority POC school system? We switched around the order of the factors for this second graph in order to see if we noticed anything new. Now, we can see a slight negative association between the percentage of students of color and total enrollment, and a strong negative association between both math scores and the percentage of students living in poverty and the percentage of English language learners and math scores. "],["interactive-component.html", "Chapter 5 Interactive component", " Chapter 5 Interactive component This interactive scatterplot looks at the relationship between a school’s percentage of white students and ELA test scores. In the plot, there is a large cluster of points where we observe many schools who have between 0 and 10% white students and mean scores between 585 and 615. Beyond this cluster, we can see a slightly positive association between a school’s percentage of white students and their test scores. As mentioned in the previous section, it is important to question the school system and standardized tests that display a positive association between whiteness and academic success, especially when all of the districts in our data are majority students of color. In our D3 visualization, each click on a point returns the mean ELA test score for the percentage of white students at a school. "],["conclusion.html", "Chapter 6 Conclusion", " Chapter 6 Conclusion One of our biggest findings was that Math and ELA scores (by district) were relatively similar for each of the three years that our data was collected, despite the fact that the Covid-19 pandemic impacted them in nearly opposite ways. As expected, success in one subject usually came with success in the other. Secondly, there was a wide range of variance in scores (for both subjects) across Districts. The demographics that we explored in part 2, such as percentage of students in poverty and percentage of English language learners, all have an effect on test scores (along with other things that are not included in the data). Finally, as the general public is slowly starting to realize, there are many issues with standardized testing and the many negative correlations that we saw in our parallel coordinates plots lend credence to this idea. There is countless research available that details the harmful effects of these tests in an attempt to abolish them altogether. Here is a great place to start reading if you are interested: https://www.nea.org/advocating-for-change/new-from-nea/racist-beginnings-standardized-testing Now, moving to the limitations of our research. Standardized testing is not always the best measure of academic success; we used the two interchangeably in our analysis of the data, because we do not have access to the large scale, quantitative and qualitative data that is necessary to paint the full picture of a student’s academic performance. As mentioned before, the way we viewed race in our analysis was binary and did not leave much room for nuance that exists within the classroom and beyond Looking forward, introducing the school satisfaction survey and integrating it into our analysis of the education that a school/district is provides its students would be interesting. The aforementioned survey can be found here: https://infohub.nyced.org/reports/school-quality/nyc-school-survey The biggest lesson we learned is data cleaning is a long and detailed process that truly shapes your visualizations and analysis. You may have to go back and forth between cleaning/transforming the data and visualizing/analyzing multiple times, if you really want to view your data from as many different perspectives as possible. "],["appendix.html", "Chapter 7 Appendix 7.1 Data Cleaning/Transformation", " Chapter 7 Appendix 7.1 Data Cleaning/Transformation Reading in the six different data sets from the sources listed in Section 2.2 Data Transformation Prepping the individual datasets to be joined, starting with getting rid of unnecessary years Converting years of demographics spreadsheets to single year format instead of school year Renaming the “District” column in the demographics dataset so it matches with the ELA/Math ones by district Converting “Year” columns of both demographics datasets &amp; “District” column of the demographic district dataset to numeric so they match the Math/ELA datasets Selecting the rows where data for “All Grades” is used in the Math/ELA spreadsheets Renaming all of the columns in the Math/ELA spreadsheets so we know which scores correspond to which test after everything is joined. The “_m” suffix corresponds to a Math score, and the “_e” suffix corresponds to an ELA score Joining datasets (one for school, one for district) Adding a new column in each dataframe that shows the percentage of students in a given district/school who sat for testing in a given year Getting rid of unnecessary columns in each of the combined dataframes Getting rid of the “Above 95%” entries in each dataframe- replacing it with 0.95 for the sake of analysis. Then converting numeric columns to numeric again Imputing all missing values with the mean of the column; too many rows/columns to create a heatmap and only 2 missing values (one in the Math scores and one in the ELA scores) so we will just impute them with the mean value for each category and analyze the other missing values later Creating a % POC column (that sums all of the other races) for racial analysis of data Renaming specific columns for visibility in plots Writing two new csv’s so we don’t have to touch any of the old dataframes/csv’s anymore "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
