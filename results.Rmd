# Results
```{r, include=FALSE}
library(GGally)
library(tidyverse)
library(readxl)
library(skimr)
library(ggplot2)
library(ggridges)
library(ggpubr)
library(formattable)
library(RColorBrewer)
library(moments)
library(echarts4r)
library(abdiv)
```


```{r, include=FALSE}
school <- read_csv("../School.csv")
district <- read_csv("../District.csv")
```


## Analyzing standardized test scores 

### Descriptive Statistics

```{r}

get_desc_stat = function(df, year, stat, subject) {
  
  ## Filtering by subject & year: 
  
  if (subject == "Math") {
    data = df |> filter(Year == year) |> pull(`Mean Scale Score_m`)
  }
  else if (subject == "ELA") {
    data =  df |> filter(Year == year) |> pull(`Mean Scale Score_e`)
  }
  
  ## Retrieving the desired stat for the desired subject:

 if (stat == "var") {
   desc_stat = var(data) |> round(digits = 2)
 }
  
  else if (stat == "sd") {
    desc_stat = sd(data)  |> round (digits = 2)
  }
  
  else if (stat == "mean") {
    desc_stat = mean(data)  |> round (digits = 2)
  } 
  
  else if (stat == "max") {
    desc_stat = max(data)  |> round (digits = 2)
  }
  
  else if (stat == "min") {
    desc_stat = min(data)  |> round (digits = 2)
  } 
  
  else if (stat == "kurtosis") {
    desc_stat = kurtosis(data)  |> round (digits = 2)
  }
  
  else if (stat == "skewness") {
    desc_stat = skewness(data)  |> round (digits = 2)
  }
  
  else if (stat == "Shapiro-Wilk p value") {
    desc_stat = shapiro.test(data)$p.value  |> round (digits = 2)
  }
  
  
  else {
    stop("Invalid stat provided")
  }
  return(desc_stat)
}


get_stat_matrix = function(df, years, stats, subject) {
  
  stat_matrix = matrix(data = NA, nrow = length(stats), ncol = length(years))
  
  for (j in 1:length(years)) {
    
    for (i in 1:length(stats)) {
      
      stat_matrix[i,j] = get_desc_stat(df, years[j], stats[i], subject)
      
    }
    
  }
  
  stat_df = data.frame(stat_matrix)
  colnames(stat_df) = years
  rownames(stat_df) = stats
  return(stat_df)
}

desc_stats = c("min", "max", "mean", "sd", "var","kurtosis", "skewness", "Shapiro-Wilk p value")
test_years = c("2018", "2019", "2022")

formattable(get_stat_matrix(school, test_years, desc_stats, "Math"))
formattable(get_stat_matrix(school, test_years, desc_stats, "ELA"))
```

### Reading vs. Math Scatterplot
In investigating the relationship between Reading and Math scores, we started very broad by asking ourselves if there is a correlation between success on Math & success on ELA. We chose to break this down at the school level, because there is a lot more data for us to work with. 

```{r}
r_v_m <- ggplot(data = school) +
       geom_point(aes(x = school$`Mean Scale Score_e`, y = school$`Mean Scale Score_m`), color = "lightskyblue", alpha =0.5) + 
       xlab('Mean ELA Score') +
       ylab('Mean Math Score') +
       ggtitle('Test Scores by School') +
       facet_wrap(~Year) 
r_v_m + geom_abline(color = "navyblue")

```

The graphs above are three scatterplots of reading vs math test scores, separated based on the year the test was taken. The two main takeaways here are that there seems to be a strong positive correlation between reading and math scores in all three years, as one might expect. In other words, schools that performed well in math usually did well on reading too, and vice-versa. There were a few outliers each year, where some schools did noticeably better on math than on reading. There were also a few, less noticeable, schools who performed slightly better on ELA than on math.  


### Correlation Analysis

Let's find the correlation between the Math and ELA scores to gain more insight on them analytically: 

Since the Math and ELA scores are not normally distributed in any year we will use the Spearman's correlation to examine the strength of the linear relationship between scores in each year. The data meets the assumptions for calculating Spearman's correlation coefficient because test scores each year are on an interval scale, they represent paired observations, and they have a monotonic relationship (as shown above). This is what we get: 

```{r, echo = FALSE, warning=FALSE}
get_spearman_corr = function(df, year) {
  math = df |> filter(Year == year) |> pull(`Mean Scale Score_m`)
  ela = df |> filter(Year == year) |> pull(`Mean Scale Score_e`)
  spearman_result <- cor.test(math, ela, method = "spearman")$estimate |> round(3)
  return(spearman_result)
}

get_corr_matrix = function(df, years) {
  corr_matrix = matrix(data = NA, nrow = 1, ncol = length(years))
  for (i in 1:length(years)) {
      corr = get_spearman_corr(df, years[i])
      corr_matrix[1,i] = corr
  }
  corr_df = data.frame(corr_matrix)
  colnames(corr_df) = years
  rownames(corr_df) = "Spearman correlation coefficient"
  return(corr_df)
}

formattable(get_corr_matrix(school, c("2018", "2019", "2022")))

```


The second big takeaway from these scatterplots is that math scores were much lower in 2022 than in years prior. There is also more variance in scores in 2022, which is demonstrated by the relatively lower correlation coefficient and the higher variance of our scatterplot than in the other two years. We can likely attribute this to the onset of the Covid-19 global pandemic, which abruptly forced students to adapt to online learning for anywhere between six months to an entire school year.

Let's look at the spread of the scores during these years: 

Looking at this table we can confirm that the variance was higher for Math & ELA in 2022. 

### Density Histogram of Test Scores

Now that we've investigated the relationship between success on both exams, we want to know which exam students actually performed better on, over the years. Again, we are looking at this data on the school level because there is more data to work with. 

```{r}
scores = school |> select(Year, `Mean Scale Score_e`, `Mean Scale Score_m`, DBN) |>
  pivot_longer(cols = c("Mean Scale Score_e", "Mean Scale Score_m")) |>
  mutate(Test = case_when(name == "Mean Scale Score_e" ~ "ELA",
                   name == "Mean Scale Score_m" ~ "Math")) |>
           dplyr::select(-"name") |> 
           rename(score = value, year = Year)


ggplot(data = scores, aes(score, fill = Test)) + 
  geom_density(alpha = 0.5) + 
  facet_wrap(~year) + 
  theme_bw(14) + 
  scale_fill_manual(values = c("ELA" = "lightskyblue", "Math" = "navyblue"))
  
```




Looking at our density histograms, we can see that there is a lot of overlap between scores in both subjects in this three year sample size. At first glance, it seems like student's are performing slightly better on ELA than Math.

### Confidence Intervals

In order to test the significance of the difference in test scores, we can utilize the t-test. Our null-hypothesis is that the two sample means are equal (or that the test scores are the same).




```{r echo=FALSE}
get_wilcox_test = function(year, df) {
  x = df |> filter(year == year, Test == "Math") |> pull(score)
  y = df |> filter(year == year, Test == "ELA") |> pull(score)
  test = wilcox.test(x,
       y, 
       conf.int = TRUE, 
       conf_level = 0.95, 
       paired = TRUE,
       mu = 0)
  return(test)
}


get_conf_int_table = function(df) {
  num_years = length(df$year |> unique())
  conf_int_matrix = matrix(data = NA, nrow = num_years, ncol = 3)
  
  for (i in 1:num_years) {
    current_year = unique(df$year)[i]
    conf_int = get_wilcox_test(current_year, df)$conf.int
    conf_int_matrix[i,1] = conf_int[1] |> round(digits = 3)
    conf_int_matrix[i,2] = conf_int[2] |> round(digits = 3)
    conf_int_matrix[i,3] = get_wilcox_test(current_year, df)$p.value |> round(digits = 3)
    
  }
  
  conf_int_df = data.frame(conf_int_matrix)
  rownames(conf_int_df) = df$year |> unique()
  colnames(conf_int_df) = c("Lower boundary", "Upper boundary", "Wilcox test p-value")
  
  return(formattable(conf_int_df))
}

get_conf_int_table(scores)
```

Looking at the result of our t-test, we cannot reject the null hypothesis that our two sample means are the same, even at the 1% level of significance! Therefore, there is no evidence of a significant difference between math & reading scores during the three year period that our data comes from.  

Even when we repeat the test only looking at the year 2022 (where we noticed a bigger difference than years prior in our density histogram), there is still not enough evidence to reject the null hypothesis that the two sample means are the same, once again at the 1% level of significance. 


## Analyzing student demographics

### Race at the citywide level

```{r}

citywide = school |> 
           mutate(Asian = `Total Enrollment`* `% Asian`,
                  Black = `Total Enrollment`* `% Black`,
                  Hispanic = `Total Enrollment`* `% Hispanic`,
                  White = `Total Enrollment`* `% White`,
                  Other = `Total Enrollment`* `% Native American` + `Total Enrollment`* `% Multi-Racial`,
                  ELL = `Total Enrollment`* `% ELL`,
                  SWD = `Total Enrollment`* `% SWD`,
                  Poverty = `Total Enrollment`* `% Poverty`)|> 
           select(Asian, Black, Hispanic, White, Other, Year, ELL, SWD, Poverty, `Total Enrollment`, ENI) |> 
           group_by(Year) |> 
           summarise(Asian = sum(Asian)/sum(`Total Enrollment`), 
                     Black = sum(Black)/sum(`Total Enrollment`),
                     Hispanic = sum(Hispanic)/sum(`Total Enrollment`),
                     White = sum(White)/sum(`Total Enrollment`),
                     Other = sum(Other)/sum(`Total Enrollment`),
                     ELL = sum(ELL)/sum(`Total Enrollment`), 
                     SWD = sum(SWD)/sum(`Total Enrollment`), 
                     Poverty = sum(Poverty)/sum(`Total Enrollment`), 
                     ENI = mean(ENI)) |> 
           mutate(Year = as.factor(Year))
```


```{r}
citywide_agg = school |> 
           mutate(Asian = `Total Enrollment`* `% Asian`,
                  Black = `Total Enrollment`* `% Black`,
                  Hispanic = `Total Enrollment`* `% Hispanic`,
                  White = `Total Enrollment`* `% White`,
                  Other = `Total Enrollment`* `% Native American` + `Total Enrollment`* `% Multi-Racial`,
                  ELL = `Total Enrollment`* `% ELL`,
                  SWD = `Total Enrollment`* `% SWD`,
                  Poverty = `Total Enrollment`* `% Poverty`)|> 
           select(Asian, Black, Hispanic, White, Other, Year, ELL, SWD, Poverty, `Total Enrollment`, ENI) |> 
           summarise(Asian = sum(Asian)/sum(`Total Enrollment`), 
                     Black = sum(Black)/sum(`Total Enrollment`),
                     Hispanic = sum(Hispanic)/sum(`Total Enrollment`),
                     White = sum(White)/sum(`Total Enrollment`),
                     Other = sum(Other)/sum(`Total Enrollment`),
                     ELL = sum(ELL)/sum(`Total Enrollment`), 
                     SWD = sum(SWD)/sum(`Total Enrollment`), 
                     Poverty = sum(Poverty)/sum(`Total Enrollment`), 
                     ENI = mean(ENI))

citywide_donut = citywide_agg |> 
           select(c("Asian", "Black", "Hispanic", "White", "Other")) |> 
           data.table::transpose()

rownames(citywide_donut) = colnames(citywide)[2:6]

citywide_donut = citywide_donut |> 
  rownames_to_column("race") |> 
  rename(percentage = "V1")

citywide_donut |> 
  e_charts(race) |> 
  e_pie(percentage, radius = c("50%", "70%"), itemStyle = list(borderRadius = 10, borderColor = '#fff', borderWidth = 0.5)) |> 
  e_toolbox_feature(feature = "restore") |> 
  e_toolbox_feature(feature = "magicType") |> 
  e_toolbox_feature("dataView") |> 
  e_toolbox_feature("saveAsImage") |> 
  e_tooltip(trigger = "axis") |> 
  e_legend(right = 0, 
           orient = "vertical",
           top = 50) |> 
  e_color(color = brewer.pal(n = 5, name = "Blues")) |> 
  e_title(text = "Citywide Racial Demographics of NYC Students", subtext = "Using aggregated data from 2018, 2019, and 2022", left = "center", top = 5)
  
```



### Other demographics at the citywide level

```{r}
citywide |> 
    e_charts(Year) |> 
    e_bar(ELL, name = "English language learners", stack = "grp1") |> 
    e_bar(SWD, name = "Students with disabilities", stack = "grp2") |> 
    e_bar(Poverty, name = "Students living in poverty", stack = "grp3") |> 
    e_bar(ENI, name = "Economic Need Index", stack = "grp4") |> 
    e_toolbox_feature(feature = "restore") |> 
    e_toolbox_feature(feature = "magicType", type = list("line")) |> 
    e_toolbox_feature("dataView") |> 
    e_toolbox_feature("saveAsImage") |> 
    e_tooltip(trigger = "axis") |> 
    e_legend(orient = "horizontal",
           bottom = 10) |> 
    e_color(color = brewer.pal(n = 4, name = "Blues"))
```



### Diversity score
```{r}
test_simpson = citywide |> filter(Year == "2018") |> select (-c("Year")) |> select(c("Asian", "Black", "Hispanic", "White", "Other"))
simpson(test_simpson)
```

(Diversity Index) [https://geographyfieldwork.com/Simpson'sDiversityIndex.htm#:~:text=Simpson's%20Diversity%20Index%20is%20a,evenness%20increase%2C%20so%20diversity%20increases.&text=The%20value%20of%20D%20ranges%20between%200%20and%201.]


### Descriptive statistics

```{r}
district_agg = district |> 
               mutate(Asian = `Total Enrollment`* `% Asian`,
                  Black = `Total Enrollment`* `% Black`,
                  Hispanic = `Total Enrollment`* `% Hispanic`,
                  White = `Total Enrollment`* `% White`,
                  Other = `Total Enrollment`* `% Native American` + `Total Enrollment`* `% Multi-Racial`,
                  ELL = `Total Enrollment`* `% ELL`,
                  SWD = `Total Enrollment`* `% SWD`,
                  Poverty = `Total Enrollment`* `% Poverty`)|> 
           select(District, Asian, Black, Hispanic, White, Other, ELL, SWD, Poverty, `Total Enrollment`, ENI) |> 
           group_by(District) |> 
           summarise(Asian = sum(Asian)/sum(`Total Enrollment`), 
                     Black = sum(Black)/sum(`Total Enrollment`),
                     Hispanic = sum(Hispanic)/sum(`Total Enrollment`),
                     White = sum(White)/sum(`Total Enrollment`),
                     Other = sum(Other)/sum(`Total Enrollment`),
                     ELL = sum(ELL)/sum(`Total Enrollment`), 
                     SWD = sum(SWD)/sum(`Total Enrollment`), 
                     Poverty = sum(Poverty)/sum(`Total Enrollment`), 
                     ENI = mean(ENI)) |> 
            mutate_all(funs(round(., digits = 3)))



race_formatter <- formatter("span",
                            style = x ~ style(
                              display = "block",
                              padding = "5px",
                              `border-radius` = "4px",
                              `background-color` = ifelse(x >= 0.5, "cornflowerblue", ""),
                              color = ifelse(x >= 0.5, "white", "")
                            ))



formattable(district_agg, list(
  Black = race_formatter,
  Asian = race_formatter, 
  Hispanic = race_formatter,
  White = race_formatter
))
```





## How does demographic information impact student performance

```{r}
lm_school = school |> select(c(`Mean Scale Score_e`, `Mean Scale Score_m`, `% Asian`, `% Poverty`, `% ELL`, `% SWD`, `% White`, `% Black`, `% Hispanic`))
reg = lm(`Mean Scale Score_e` ~ ., data = lm_school)
summary(reg)
```

