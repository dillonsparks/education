# Results

```{r, include=FALSE}
library(GGally)
library(tidyverse)
library(readxl)
library(skimr)
library(ggplot2)
library(ggridges)
library(ggpubr)
library(formattable)
library(RColorBrewer)
library(moments)
library(echarts4r)
library(abdiv)
library(lmtest)
library(bestglm)
```

```{r, include=FALSE}
school <- read_csv("../School.csv")
district <- read_csv("../District.csv")
```

## Analyzing standardized test scores

In order to investigate the larger question of how student demographics impact test scores, we need to take analyze the test scores themselves.

### Descriptive Statistics

First, we'll start off by looking at a few descriptive statistics to see what they tell us about the Math and ELA test scores. The tables below contain basic descriptive statistics for each exam over the years. Each data point, i.e. test score, represents the mean score from grades 3-8 in the respective exam.

```{r}

get_desc_stat = function(df, year, stat, subject) {
  
  ## Filtering by subject & year: 
  
  if (subject == "Math") {
    data = df |> filter(Year == year) |> pull(`Mean Scale Score_m`)
  }
  else if (subject == "ELA") {
    data =  df |> filter(Year == year) |> pull(`Mean Scale Score_e`)
  }
  
  ## Retrieving the desired stat for the desired subject:

 if (stat == "var") {
   desc_stat = var(data) |> round(digits = 2)
 }
  
  else if (stat == "sd") {
    desc_stat = sd(data)  |> round (digits = 2)
  }
  
  else if (stat == "mean") {
    desc_stat = mean(data)  |> round (digits = 2)
  } 
  
  else if (stat == "max") {
    desc_stat = max(data)  |> round (digits = 2)
  }
  
  else if (stat == "min") {
    desc_stat = min(data)  |> round (digits = 2)
  } 
  
  else if (stat == "kurtosis") {
    desc_stat = kurtosis(data)  |> round (digits = 2)
  }
  
  else if (stat == "skewness") {
    desc_stat = skewness(data)  |> round (digits = 2)
  }
  
  else if (stat == "Shapiro-Wilk p value") {
    desc_stat = shapiro.test(data)$p.value  |> round (digits = 2)
  }
  
  
  else {
    stop("Invalid stat provided")
  }
  return(desc_stat)
}


get_stat_matrix = function(df, years, stats, subject) {
  
  stat_matrix = matrix(data = NA, nrow = length(stats), ncol = length(years))
  
  for (j in 1:length(years)) {
    
    for (i in 1:length(stats)) {
      
      stat_matrix[i,j] = get_desc_stat(df, years[j], stats[i], subject)
      
    }
    
  }
  
  stat_df = data.frame(stat_matrix)
  colnames(stat_df) = years
  rownames(stat_df) = stats
  return(stat_df)
}

desc_stats = c("min", "max", "mean", "sd", "var","kurtosis", "skewness", "Shapiro-Wilk p value")
test_years = c("2018", "2019", "2022")

formattable(get_stat_matrix(school, test_years, desc_stats, "Math"))

```

Here are a few notes about this table:

-   The p-value for our Shapiro-Wilk normality test is 0 each year. This means the distribution of test scores is not normal in any year, and we must keep this in mind for any analyses/visualizations done with this data.

-   2022 was an interesting year because    

```{r}
formattable(get_stat_matrix(school, test_years, desc_stats, "ELA"))
```

### Reading vs. Math Scatterplot

In investigating the relationship between Reading and Math scores, we started very broad by asking ourselves: <b> is there a correlation between success on Math & success on ELA? </b> We chose to break this down at the school level, because there is more data for us to work with compared to scores at the district level.

   

```{r}
r_v_m <- ggplot(data = school) +
       geom_point(aes(x = school$`Mean Scale Score_e`, y = school$`Mean Scale Score_m`), color = "lightskyblue", alpha =0.5) + 
       xlab('Mean ELA Score') +
       ylab('Mean Math Score') +
       labs(title = 'Reading vs Math Scores by School', subtitle = "Faceted by Year") +
       facet_wrap(~Year) + 
       theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))
r_v_m + geom_abline(color = "navyblue")

```

   

The graphs above are three scatterplots of reading vs math test scores, separated based on the year the test was taken. The first main takeaway here is that there seems to be a strong positive correlation between reading and math scores in all three years, as one might expect. In other words, schools that performed well in math usually did well on reading too, and vice-versa. There were a few outliers each year, where some schools did noticeably better on math than on reading. There were also a few, less noticeable, schools who performed slightly better on ELA than on math.

The second big takeaway from these scatterplots is that math scores were noticeably lower in 2022 than in years prior. There is also more variance in scores in 2022, which is demonstrated by higher variance of our scatterplot than in the other two years. We can likely attribute this to the onset of the Covid-19 global pandemic, which abruptly forced students to adapt to online learning for anywhere between six months to an entire school year.

   

### Correlation Analysis

Now that we have examined the linear relationship between Math and ELA scores graphically, let's see if we can find any more information by doing so analytically. 

We will use the Spearman's correlation to examine the strength of the linear relationship between scores in each year since they are not normally distributed. The data meets the assumptions for calculating Spearman's correlation coefficient because test scores each year are on an interval scale, they represent paired observations, and they have a monotonic relationship (as shown above). This is what we get:

   

```{r, echo = FALSE, warning=FALSE}
get_spearman_corr = function(df, year) {
  math = df |> filter(Year == year) |> pull(`Mean Scale Score_m`)
  ela = df |> filter(Year == year) |> pull(`Mean Scale Score_e`)
  spearman_result <- cor.test(math, ela, method = "spearman")$estimate |> round(3)
  return(spearman_result)
}

get_corr_matrix = function(df, years) {
  corr_matrix = matrix(data = NA, nrow = 1, ncol = length(years))
  for (i in 1:length(years)) {
      corr = get_spearman_corr(df, years[i])
      corr_matrix[1,i] = corr
  }
  corr_df = data.frame(corr_matrix)
  colnames(corr_df) = years
  rownames(corr_df) = "Spearman correlation coefficient"
  return(corr_df)
}

formattable(get_corr_matrix(school, c("2018", "2019", "2022")))

```

   

Looking at this table, we can see that the linear relationship between scores on the two exams is fairly strong, as expected. Furthermore, the correlation coefficient was slightly lower in 2022 as we saw from our scatterplot. Generally speaking, we know that a relatively high achieveing Math school also did well on ELA (and vice-versa). However, this leads us to wonder <b> is there a difference between Math and ELA scores over the years?</b>

   

### Density Histogram of Test Scores

   

Again, we will start with a visualization to investigate the question of which exam students actually performed better on, over the years. Again, we are looking at this data on the school level because there is more data to work with, and thus, more nuance to be uncovered.

   

```{r}
scores = school |> select(Year, `Mean Scale Score_e`, `Mean Scale Score_m`, DBN) |>
  pivot_longer(cols = c("Mean Scale Score_e", "Mean Scale Score_m")) |>
  mutate(Test = case_when(name == "Mean Scale Score_e" ~ "ELA",
                   name == "Mean Scale Score_m" ~ "Math")) |>
           dplyr::select(-"name") |> 
           rename(score = value, year = Year)


ggplot(data = scores, aes(score, fill = Test)) + 
  geom_density(alpha = 0.5) + 
  facet_wrap(~year) + 
  theme_bw(14) + 
  scale_fill_manual(values = c("ELA" = "lightskyblue", "Math" = "navyblue"))
  
```

   

Looking at our density histograms, we can see that there is a lot of overlap between scores in both subjects in this three year sample size. At first glance, the relatively higher concentration of ELA scores from 600 onwards suggests that student's performed slightly better on ELA than Math each year. This is particularly true in 2022 where scores on the exams are most distinguishable. 

   

### Confidence Intervals

   

In order to test the significance of the difference in test scores, we can utilize the Wilcox Test to estimate the difference . We cannot use the traditional paired t-test because our data is not normal. Our null-hypothesis is that the two sample means are equal (or that the test scores for ELA and Math are the same).

   

```{r echo=FALSE}
get_wilcox_test = function(year, df) {
  x = df |> filter(year == year, Test == "Math") |> pull(score)
  y = df |> filter(year == year, Test == "ELA") |> pull(score)
  test = wilcox.test(x,
       y, 
       conf.int = TRUE, 
       conf_level = 0.99, 
       paired = TRUE,
       mu = 0)
  return(test)
}


get_conf_int_table = function(df) {
  num_years = length(df$year |> unique())
  conf_int_matrix = matrix(data = NA, nrow = num_years, ncol = 3)
  
  for (i in 1:num_years) {
    current_year = unique(df$year)[i]
    conf_int = get_wilcox_test(current_year, df)$conf.int
    conf_int_matrix[i,1] = conf_int[1] |> round(digits = 3)
    conf_int_matrix[i,2] = conf_int[2] |> round(digits = 3)
    conf_int_matrix[i,3] = get_wilcox_test(current_year, df)$p.value |> round(digits = 3)
    
  }
  
  conf_int_df = data.frame(conf_int_matrix)
  rownames(conf_int_df) = df$year |> unique()
  colnames(conf_int_df) = c("Lower boundary", "Upper boundary", "Wilcox test p-value")
  
  return(formattable(conf_int_df))
}

get_conf_int_table(scores)
```

   

Looking at the result of our test for each year (<b> p = 0 < 0.01 </b>), we can reject the null hypothesis that our two sample means are the same, even at the 1% level of significance! Therefore, we have evidence of a statistically significant difference between the median Math & ELA scores in each year observed. It is notable that the 99% confidence interval, (-2.671, -2.384), is the same for each year. Thus, we are 99% confident that the true median difference between Math and ELA scores is between (-2.671, -2.384). 

### Main Takeaways

In summary, we know schools that performed relatively well on one exam were also successful on the other. Furthermore, there is evidence that students performed about 3 points better on ELA than Math, each year. 

   

## Analyzing student demographics

   

### Race at the citywide level

   

```{r}

citywide = school |> 
           mutate(Asian = `Total Enrollment`* `% Asian`,
                  Black = `Total Enrollment`* `% Black`,
                  Hispanic = `Total Enrollment`* `% Hispanic`,
                  White = `Total Enrollment`* `% White`,
                  Other = `Total Enrollment`* `% Native American` + `Total Enrollment`* `% Multi-Racial`,
                  ELL = `Total Enrollment`* `% ELL`,
                  SWD = `Total Enrollment`* `% SWD`,
                  Poverty = `Total Enrollment`* `% Poverty`)|> 
           select(Asian, Black, Hispanic, White, Other, Year, ELL, SWD, Poverty, `Total Enrollment`, ENI) |> 
           group_by(Year) |> 
           summarise(Asian = sum(Asian)/sum(`Total Enrollment`), 
                     Black = sum(Black)/sum(`Total Enrollment`),
                     Hispanic = sum(Hispanic)/sum(`Total Enrollment`),
                     White = sum(White)/sum(`Total Enrollment`),
                     Other = sum(Other)/sum(`Total Enrollment`),
                     ELL = sum(ELL)/sum(`Total Enrollment`), 
                     SWD = sum(SWD)/sum(`Total Enrollment`), 
                     Poverty = sum(Poverty)/sum(`Total Enrollment`), 
                     ENI = mean(ENI)) |> 
           mutate(Year = as.factor(Year))
```

```{r}
citywide_agg = school |> 
           mutate(Asian = `Total Enrollment`* `% Asian`,
                  Black = `Total Enrollment`* `% Black`,
                  Hispanic = `Total Enrollment`* `% Hispanic`,
                  White = `Total Enrollment`* `% White`,
                  Other = `Total Enrollment`* `% Native American` + `Total Enrollment`* `% Multi-Racial`,
                  ELL = `Total Enrollment`* `% ELL`,
                  SWD = `Total Enrollment`* `% SWD`,
                  Poverty = `Total Enrollment`* `% Poverty`)|> 
           select(Asian, Black, Hispanic, White, Other, Year, ELL, SWD, Poverty, `Total Enrollment`, ENI) |> 
           summarise(Asian = sum(Asian)/sum(`Total Enrollment`), 
                     Black = sum(Black)/sum(`Total Enrollment`),
                     Hispanic = sum(Hispanic)/sum(`Total Enrollment`),
                     White = sum(White)/sum(`Total Enrollment`),
                     Other = sum(Other)/sum(`Total Enrollment`),
                     ELL = sum(ELL)/sum(`Total Enrollment`), 
                     SWD = sum(SWD)/sum(`Total Enrollment`), 
                     Poverty = sum(Poverty)/sum(`Total Enrollment`), 
                     ENI = mean(ENI))

citywide_donut = citywide_agg |> 
           select(c("Asian", "Black", "Hispanic", "White", "Other")) |> 
           data.table::transpose()

rownames(citywide_donut) = colnames(citywide)[2:6]

citywide_donut = citywide_donut |> 
  rownames_to_column("race") |> 
  rename(percentage = "V1")

citywide_donut |> 
  e_charts(race) |> 
  e_pie(percentage, radius = c("50%", "70%"), itemStyle = list(borderRadius = 10, borderColor = '#fff', borderWidth = 0.5)) |> 
  e_toolbox_feature(feature = "restore") |> 
  e_toolbox_feature(feature = "magicType") |> 
  e_toolbox_feature("dataView") |> 
  e_toolbox_feature("saveAsImage") |> 
  e_tooltip(trigger = "axis") |> 
  e_legend(right = 0, 
           orient = "vertical",
           top = 50) |> 
  e_color(color = brewer.pal(n = 5, name = "Blues")) |> 
  e_title(text = "Citywide Racial Demographics of NYC Students", subtext = "Using aggregated data from 2018, 2019, and 2022", left = "center", top = 5)
  
```

       

### Other demographics at the citywide level

   

```{r}
citywide |> 
    e_charts(Year) |> 
    e_bar(ELL, name = "English language learners", stack = "grp1") |> 
    e_bar(SWD, name = "Students with disabilities", stack = "grp2") |> 
    e_bar(Poverty, name = "Students living in poverty", stack = "grp3") |> 
    e_bar(ENI, name = "Economic Need Index", stack = "grp4") |> 
    e_toolbox_feature(feature = "restore") |> 
    e_toolbox_feature(feature = "magicType", type = list("line")) |> 
    e_toolbox_feature("dataView") |> 
    e_toolbox_feature("saveAsImage") |> 
    e_tooltip(trigger = "axis") |> 
    e_legend(orient = "horizontal",
           bottom = 10) |> 
    e_color(color = brewer.pal(n = 4, name = "Blues"))
```

   

### Descriptive statistics & Diversity scores

   

((Diversity Index) [[https://geographyfieldwork.com/Simpson'sDiversityIndex.htm#](https://geographyfieldwork.com/Simpson'sDiversityIndex.htm#){.uri}:\~:text=Simpson's%20Diversity%20Index%20is%20a,evenness%20increase%2C%20so%20diversity%20increases.&text=The%20value%20of%20D%20ranges%20between%200%20and%201.] )

```{r}

district$Diversity = apply(district[,c("% Asian", "% Black", "% Hispanic", "% White", "% Multi-Racial", "% Native American", "% Missing Race/Ethnicity Data")], 1, simpson)


district_agg = district |> 
               mutate(Asian = `Total Enrollment`* `% Asian`,
                  Black = `Total Enrollment`* `% Black`,
                  Hispanic = `Total Enrollment`* `% Hispanic`,
                  White = `Total Enrollment`* `% White`,
                  Other = `Total Enrollment`* `% Native American` + `Total Enrollment`* `% Multi-Racial`,
                  ELL = `Total Enrollment`* `% ELL`,
                  SWD = `Total Enrollment`* `% SWD`,
                  Poverty = `Total Enrollment`* `% Poverty`)|> 
           select(District, Diversity, Asian, Black, Hispanic, White, ELL, SWD, Poverty, `Total Enrollment`, ENI) |> 
           group_by(District) |> 
           summarise(Asian = sum(Asian)/sum(`Total Enrollment`), 
                     Black = sum(Black)/sum(`Total Enrollment`),
                     Hispanic = sum(Hispanic)/sum(`Total Enrollment`),
                     White = sum(White)/sum(`Total Enrollment`),
                     ELL = sum(ELL)/sum(`Total Enrollment`), 
                     SWD = sum(SWD)/sum(`Total Enrollment`), 
                     Poverty = sum(Poverty)/sum(`Total Enrollment`), 
                     ENI = mean(ENI),
                     Diversity = mean(Diversity)) |> 
            mutate_all(funs(round(., digits = 2)))



get_significant_values = function(df, column) {
  
  if (column != "District") {
  col_mean = df |> pull(column) |> mean()  
  col_sd = df |> pull(column) |> sd()
  lower = col_mean - 1.5 * col_sd
  upper = col_mean + 1.5 * col_sd
  
  val = df |> pull(column)
  lower_vals = val[val <= lower]
  upper_vals = val[val >= upper]
  
  return(list(lower = lower_vals, upper = upper_vals))
    
  }
}

generate_column_formatter <- function(df, column) {
  sig_vals <- get_significant_values(df, column)
  
  formatter("span",
            style = x ~ style(
              display = "block",
              padding = "5px",
              `border-radius` = "2px",
              
              `text-align` = "center",
              `vertical-align` = "middle"
            ))
}



generate_column_formatter = function(df, column) {
  
  formatter("span",
  style = x ~ style(
                    display = "block",
                    padding = "5px",
                    `border-radius` = "2px",
                    `background-color` = ifelse(
                                                x %in% get_significant_values(df, column)$lower, "#015C92",
                                                ifelse(x %in% get_significant_values(df, column)$upper, "#BCE6FF", "")
                                                ),
                     color = ifelse(x %in% unlist(get_significant_values(df, column)), "white", ""),
                    `text-align` = "center",
                    `vertical-align` = "middle"
                    ))
}                           


formatters_list <- lapply(names(district_agg), function(column) {
  generate_column_formatter(district_agg, column)
})

# Name the list elements with the column names
names(formatters_list) <- names(district_agg)

# Apply the formatters to your data frame
formattable(district_agg, formatters_list)

```

       

## Regression Analysis

   

Need to explain which variables I am getting rid of and justify them

```{r}
school$Diversity = apply(school[,c("% Asian", "% Black", "% Hispanic", "% White", "% Multi-Racial", "% Native American", "% Missing Race/Ethnicity Data")], 1, simpson)

lm_school = school |> select(c(`Mean Scale Score_e`, `Mean Scale Score_m`, `% Poverty`, `% ELL`, `% SWD`, `ENI`, `Diversity`, `Total Enrollment`))
```

   

### Linear Regression (English)

   

```{r}
english_reg = lm(`Mean Scale Score_e` ~ `% Poverty` + `% ELL` + `% SWD` + `ENI` + `Diversity` + `Total Enrollment`, data = lm_school)
summary(english_reg)
```

   

```{r}

standardized_eng_residuals <- rstandard(english_reg)

plot(x = english_reg$fitted.values, 
     y = standardized_eng_residuals, 
     main = "Residuals vs Fitted",
     xlab = "Fitted values",
     ylab = "Standardized English Residuals")

abline(h = 0, col = "red", lwd = 2)

bptest(english_reg)


# Q-Q plot
qqnorm(standardized_eng_residuals, 
       main = "Normal Q-Q Plot")
qqline(standardized_eng_residuals, col = "red")

shapiro.test(standardized_eng_residuals)



```

       

### Linear Regression (Math scores)

   

```{r}
math_reg = lm(`Mean Scale Score_m` ~ `% Poverty` + `% ELL` + `% SWD` + `ENI` + `Diversity` + `Total Enrollment`, data = lm_school)
summary(math_reg)
```

   

```{r}
standardized_math_residuals <- rstandard(math_reg)

plot(x = math_reg$fitted.values, 
     y = standardized_math_residuals, 
     main = "Residuals vs Fitted",
     xlab = "Fitted values",
     ylab = "Standardized Math Residuals")

abline(h = 0, col = "red", lwd = 2)

bptest(math_reg)


# Q-Q plot
qqnorm(standardized_math_residuals, 
       main = "Normal Q-Q Plot")
qqline(standardized_math_residuals, col = "red")

shapiro.test(standardized_math_residuals)

```

\*\* Both linear models failed the homoscedasticity (constant variance) and normality assumptions for the standardized residuals. This means we cannot reliably interpret the results from either linear regression model. Next, we will try a Generalized Linear Model (GLM) with a Gamma link function. A Gamma link makes sense here because they are usually used when working with non-negative, continuous, and positive-skewed data.

   

### GLM (English)

       

```{r}
glm_eng = glm(`Mean Scale Score_e` ~ `% Poverty` + `% ELL` + `% SWD` + `ENI` + `Diversity` + `Total Enrollment`,  family = "Gamma"(link = log), data = lm_school)

summary(glm_eng)
```

   

### GLM (Math)

   

```{r}
glm_math = glm(`Mean Scale Score_m` ~ `% Poverty` + `% ELL` + `% SWD` + `ENI` + `Diversity` + `Total Enrollment`,  family = "Gamma"(link = log), data = lm_school)

summary(glm_math)
```

\*\*\* Still need to find out if there are any assumptions i need to make or anything to prove before interpretations \*\*\*

       
